{"cells":[{"cell_type":"code","execution_count":75,"metadata":{"executionInfo":{"elapsed":3791,"status":"ok","timestamp":1696002587403,"user":{"displayName":"Michele Cerra","userId":"09065373780753548200"},"user_tz":-120},"id":"u0FrajMwmrrN"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import tqdm\n","import time\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from google.colab import drive\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import LeaveOneOut, train_test_split\n","\n","from datetime import datetime"]},{"cell_type":"markdown","metadata":{"id":"_K2VGawAtVdQ"},"source":[" For GPU"]},{"cell_type":"code","source":["drive.mount('/content/drive')\n","\n","study_fold = '/content/drive/MyDrive/Thesis:Epilepsy/study/'\n","dataset_path = os.path.join(study_fold, \"stats/datasetRadiomicsReduced.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gobnGYOlZBNU","executionInfo":{"status":"ok","timestamp":1696001128285,"user_tz":-120,"elapsed":2496,"user":{"displayName":"Michele Cerra","userId":"09065373780753548200"}},"outputId":"ce76e743-c393-43e2-fb2e-374b15f7dba7"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":260,"metadata":{"executionInfo":{"elapsed":307,"status":"ok","timestamp":1696010230750,"user":{"displayName":"Michele Cerra","userId":"09065373780753548200"},"user_tz":-120},"id":"dBgIDUQare-e"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["df = pd.read_csv(dataset_path, index_col=\"ID\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"8d6EkMz3d5Q5","executionInfo":{"status":"error","timestamp":1696010232518,"user_tz":-120,"elapsed":1305,"user":{"displayName":"Michele Cerra","userId":"09065373780753548200"}},"outputId":"d96785cb-80f7-4a00-d64a-44bc25f465a0"},"execution_count":261,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-261-a8fc3cc8997b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1434\u001b[0m     \"\"\"\n\u001b[1;32m   1435\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mextension\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","execution_count":262,"metadata":{"executionInfo":{"elapsed":310,"status":"ok","timestamp":1696010236793,"user":{"displayName":"Michele Cerra","userId":"09065373780753548200"},"user_tz":-120},"id":"Ydsf6vmP0HAl"},"outputs":[],"source":["class DatasetDiffusionMRI(Dataset):\n","  def __init__(self, X, y):\n","    self.X = X\n","    self.y = y\n","\n","  def __len__(self):\n","    return self.X.shape[0]\n","\n","  def __getitem__(self, idx):\n","    features = self.X.iloc[idx, :].to_numpy()\n","    label = self.y.iloc[idx].to_numpy(dtype=\"float64\")\n","\n","    return features, label"]},{"cell_type":"code","source":["def looPytorch():\n","  avg_score = []\n","\n","  for train_val_idx, test_idx in LeaveOneOut().split(df):\n","    train_val = df.iloc[train_val_idx, :]\n","    test = df.iloc[test_idx, :]\n","    for train_idx, val_idx in LeaveOneOut().split(train_val):\n","      train = train_val.iloc[train_idx, :]\n","      val = train_val.iloc[val_idx, :]\n","\n","      # train the model\n","\n","      # evaluate the model, fo the hyperParameters selection\n","\n","    # Select the best model and use it for the test\n","    # test the model, compute the score and add tot the list\n","\n","  # mean of avg_score\n","  return np.mean(avg_score)\n"],"metadata":{"id":"vXp729smdPLB","executionInfo":{"status":"ok","timestamp":1696010241349,"user_tz":-120,"elapsed":350,"user":{"displayName":"Michele Cerra","userId":"09065373780753548200"}}},"execution_count":263,"outputs":[]},{"cell_type":"code","source":["X, y, y3 = df.iloc[:, 2:], df.iloc[:,:1], df.iloc[:, 1:2]\n","X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.12, shuffle=True, stratify=y3)\n","y3_train_val = y3.loc[y_train_val.index]\n","X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.14, shuffle=True, stratify=y3_train_val)"],"metadata":{"id":"wUDnLrLdjzuD","executionInfo":{"status":"ok","timestamp":1696010247101,"user_tz":-120,"elapsed":275,"user":{"displayName":"Michele Cerra","userId":"09065373780753548200"}}},"execution_count":264,"outputs":[]},{"cell_type":"code","execution_count":323,"metadata":{"id":"dcbc5rDQYt26","executionInfo":{"status":"ok","timestamp":1696012796225,"user_tz":-120,"elapsed":710,"user":{"displayName":"Michele Cerra","userId":"09065373780753548200"}}},"outputs":[],"source":["class ModelTrainer():\n","    def __init__(self, train_dataset, val_dataset, model, device, loss_fn, optimizer, batch_size):\n","        self.train_dataset = train_dataset\n","        self.val_dataset = val_dataset\n","        self.model = model.to(device)\n","        self.device = device\n","        self.loss_fn = loss_fn\n","        self.optimizer = optimizer\n","\n","        self.train_loader = DataLoader(\n","            self.train_dataset,\n","            batch_size,\n","            shuffle=True\n","        )\n","\n","        self.val_loader = DataLoader(\n","            self.val_dataset,\n","            batch_size,\n","            shuffle=True\n","        )\n","\n","        self.epoch_number = 0\n","\n","    def __trainOneEpoch(self, epoch_index, tb_writer):\n","        running_loss = 0\n","\n","        for i, data in enumerate(self.train_loader):\n","\n","            # Step 1: Get the features and the label\n","            features, labels = data\n","            features = features.to(self.device)\n","            labels = labels.to(self.device)\n","\n","            # Step 2: Zero the gradient\n","            self.optimizer.zero_grad()\n","\n","            # Step 3: Make predictions\n","            outputs = self.model(features)\n","\n","            # Step 4: Compute the loss\n","            loss = self.loss_fn(outputs, labels)\n","\n","            # - : Compute the gradient\n","            loss.backward()\n","\n","            # Step 5: Adjust weights\n","            self.optimizer.step()\n","\n","            # Data and report Statistics\n","            curr_loss = loss.item()\n","            running_loss += curr_loss\n","\n","            # since the small dataset, report the loss at each batch\n","            print(\"\\tbatch {} loss: {}\".format(i+1, curr_loss))\n","            tb_x = epoch_index*len(self.train_loader) + i + 1\n","            tb_writer.add_scalar(\"Loss/Train\", curr_loss, tb_x)\n","\n","        return running_loss/(i+1)\n","\n","\n","    def train(self, epochs):\n","        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n","        writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n","\n","        EPOCHS = epochs\n","\n","        best_vloss = 1_000_000\n","\n","        for epoch in range(EPOCHS):\n","            print(\"EPOCH {}\".format(self.epoch_number + 1))\n","\n","            # Set the model to training mode\n","            self.model.train()\n","            avg_loss = self.__trainOneEpoch(self.epoch_number, writer)\n","\n","            # Set the model to validation mode\n","            running_vloss = 0.0\n","            self.model.eval()\n","\n","            with torch.no_grad():\n","                for i, vdata in enumerate(self.val_loader):\n","                    # Get the features and the labels\n","                    features, labels = vdata\n","                    features = features.to(self.device)\n","                    labels = labels.to(self.device)\n","\n","                    voutputs = self.model(features)\n","\n","                    loss = self.loss_fn(voutputs, labels)\n","                    running_vloss +=loss\n","\n","            avg_vloss = running_vloss/(i+1)\n","            print(\"LOSS train {} valid {}\".format(avg_loss, avg_vloss))\n","\n","            # Data and report Statistics\n","            writer.add_scalars('Training vs. Validation Loss',\n","                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n","                    self.epoch_number + 1)\n","            writer.flush()\n","\n","            if avg_vloss < best_vloss:\n","                best_vloss = avg_vloss\n","                model_path = \"model_{}_{}\".format(timestamp, self.epoch_number)\n","                torch.save(self.model.state_dict(), model_path)\n","\n","            self.epoch_number += 1\n"]},{"cell_type":"markdown","metadata":{"id":"KwaqFs5V83Pv"},"source":["Creating my neural network"]},{"cell_type":"code","execution_count":324,"metadata":{"executionInfo":{"elapsed":417,"status":"ok","timestamp":1696012805529,"user":{"displayName":"Michele Cerra","userId":"09065373780753548200"},"user_tz":-120},"id":"s9mr8qnW84nw"},"outputs":[],"source":["class NeuralNetwork(nn.Module):\n","  def __init__(self, in_features: int, hidden_features: int):\n","    super().__init__()\n","\n","    self.activation = nn.ReLU()\n","\n","    self.fc1 = nn.Linear(\n","        in_features=in_features,\n","        out_features=hidden_features,\n","        dtype=torch.float64\n","    )\n","    self.fc2 = nn.Linear(\n","        in_features=hidden_features,\n","        out_features=1,\n","        dtype=torch.float64\n","    )\n","    self.sigmoid = nn.Sigmoid()\n","\n","  def forward(self, X):\n","    X = self.activation(self.fc1(X))\n","    X = self.fc2(X)\n","    X = self.sigmoid(X)\n","    return X"]},{"cell_type":"code","source":["network = NeuralNetwork(X_train.shape[1], 10000).to(device)\n","\n","model_trainer = ModelTrainer(\n","    DatasetDiffusionMRI(X_train, y_train),\n","    DatasetDiffusionMRI(X_val, y_val),\n","    network,\n","    device,\n","    nn.BCELoss(),\n","    optim.Adam(network.parameters(), lr=500),\n","    batch_size=4,\n",")"],"metadata":{"id":"xzDC5_F9qoVZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_trainer.train(1000)"],"metadata":{"id":"TCHbs_HHvpZ1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"id":"JhphK2warq2h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_loss = 1e-4\n","\n","def optimize_model():\n","  optimizer = torch.optim.Adam(params = model.parameters(), lr=1e-3)\n","\n","  while loss > target_loss:\n","    optimizer.zero_grad()\n","    outpur = model()"],"metadata":{"id":"XqPmUJq_qtAq"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}